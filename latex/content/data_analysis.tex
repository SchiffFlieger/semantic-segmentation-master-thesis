\section{About the Dataset}
\label{sec:dataset_analysis}
The dataset which is used throughout this thesis is provided by the Ministry of the Interior of the State of North Rhine-Westphalia in Germany. With the platform GEOportal~\cite{geoportal20} they offer various types of maps, like topographical maps, elevation data and orthographical footage. Most of the data is available for free download in batches. The batches used in this thesis are released under the dl-de/zero-2-0 licence. This means that the data can be used for any purpose without any restrictions or conditions.

For the purpose of this thesis there are two types of maps which prove useful. First, there is a map assembled of digital orthophotos (DOPs). A DOP is an aerial photograph of the surface of the earth (Fig.~\ref{fig:rgb_example}). It is processed to hide effects like perspective distortions or topographic features of the landscape. Also it follows a specific map projection to denote the exact spatial extents of the photograph on the earth's surface. Because of that, DOPs are great to analyze terrain types and conditions. In Section~\ref{sec:segmentation} DOPs are used to perform a semantic segmentation of land use based on the terrain surface.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.35\textwidth}
        \includegraphics[width=\textwidth]{images/dop_example/rgb}
        \caption{}
        \label{fig:rgb_example}
    \end{subfigure}
    \begin{subfigure}{0.35\textwidth}
        \includegraphics[width=\textwidth]{images/dop_example/nir}
        \caption{}
        \label{fig:nir_example}
    \end{subfigure}
    \caption[Example DOP with RGB and NIR Data]
    {\textbf{Example DOP with RGB and NIR Data}. It represents a $50\times 50~\text{meters}$ cutout of the dataset.(\subref{fig:rgb_example})~RGB color. (\subref{fig:nir_example})~NIR values.}
    \label{fig:dop_rgb_nir_example}
\end{figure}

The second map explored in this thesis contains imagery obtained by near-infrared (NIR) spectroscopy (Fig.~\ref{fig:nir_example}). They are processed in the same way as the DOPs, so they are also projected onto the earth's surface with a specific map projection. NIR data is widely applied in agriculture to monitor the cultivation of herbal products like forages and vegetables. In this thesis the NIR imagery is used to approximate vegetation density for specific regions (Section~\ref{sec:vegetation_analysis}).

The data for the maps is collected by airplanes with special cameras pointing vertically downwards. With straight east-west flight paths and significant overlap in the photographic coverage, the airplanes scan the areas. In this way, a seamless image of the earth's surface is created. The ground sample distance of the dataset is $10~\text{cm}$, i.~e. each pixel in Fig.~\ref{fig:dop_rgb_nir_example} represents a $10\times 10~\text{cm}$ square in real-world scale. With such a high resolution it is easily possible to detect objects like trees, cars or buildings. Therefore, the data provides sufficient information for the segmentation of land use. The recent data is captured with different cameras like for example the Leica DMC III or the Vexcel UltraCam UCXp~\cite{topo-image16}. Therefore, small color differences in the dataset can be expected.

\subsection{Getting the Dataset}
Both the DOP and NIR datasets are provided by the Ministry of the Interior in a few different ways. To get a quick overview, there is an online viewer~\cite{tim_online20} for most of the map types. For some specific maps like the DOPs they host a Web Map Tile Service, which allows to access the data with geographic information systems (GIS) like QGIS. Since these options require a continuous network connection, it is preferred to get a local copy of the dataset and work with that.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.70\textwidth}
        \includegraphics[width=\textwidth]{images/dop_rgb_all}
        \caption{}
        \label{fig:dop_all}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\textwidth]{images/germany_location}
        \caption{}
        \label{fig:dop_location}
    \end{subfigure}
    \caption[DOP Dataset and Location in Germany]
    {\textbf{DOP Dataset and Location in Germany}. (\subref{fig:dop_all})~The entire $248.49~\text{km}^2$ of RGB data. (\subref{fig:dop_location})~The precise location of the dataset in Germany.}
    \label{fig:all_rgb_location}
\end{figure}

For that purpose, the GEOportal has a separate download section. From there the relevant regions and map types can be selected and downloaded in a compressed bundle. The bundle contains map tiles in the JPEG 2000 file format. This is an image format that has a dense compression rate and directly contains the georeferencing information for each tile. To have a wide range of terrain types with broad variety included, we use the data for the Municipality of Arnsberg and its surroundings. This concludes to a download size of $11.5~\text{Gigabytes}$ with around $248.49~\text{km}^2$ of terrain, where each pixel represents a $10\times 10~\text{cm}$ square in scale. Figure~\ref{fig:all_rgb_location} shows the color bands of the whole dataset and its location in Germany.

It is possible to download both DOP and NIR data together in a single bundle. The JPEG files then contain four channels of pixel information. The first three channels make up the red, green and blue colors for the DOPs. And the last channel provides the scalar output of the NIR spectroscopy scan.

\subsection{Preparing the Dataset}
Before the data is ready to be used for training the models, some preprocessing steps have to be performed. In Fig.~\ref{fig:data_preprocessing} the whole preparation process is summarized briefly. The present and following sections focus on importing the whole dataset into a standardized database using various tools. Afterwards, Section~\ref{sec:image_export} explains the steps to prepare the data for the use of training. This includes rendering image tiles from the raster in the database. All preparation scripts can be found in~\cite{thesis-code20}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/data_preprocessing}
    \caption[Summary of the Data Preprocessing Steps]
    {\textbf{Summary of the Data Preprocessing Steps}. Raw data is downloaded from the GEOportal platform. Several Python scripts import the data into a PostgreSQL database. A QGIS rendering process extracts three differently sized datasets from the database.}
    \label{fig:data_preprocessing}
\end{figure}

As a first step, the whole dataset is imported into a spatial database system. By doing that, it is very easy to export the data in various data formats and tile sizes required by the reference architectures (Section~\ref{sec:ref_archs}). PostgreSQL is a powerful open-source database system. Together with PostGIS, a free and open-source extension for PostgreSQL, it is capable of performing spatial operations on image rasters and vector objects. For example, it adds database functions to merge raster tiles, calculate intersection regions or determine bounding boxes.

The PostGIS installation contains a few shell tools to import data into the database. Unfortunately, they do not support the JPEG 2000 image file format. Before the import of the data can take place, it has to be translated to one of the supported formats first. One of the most widely used formats is GeoTiff. The Tiff file standard is great, because it consists of a baseline section which contains the image information, and a meta section which can contain all kinds of meta information. For example, it can be used to store georeferencing information, which PostGIS is able to use for importing GeoTiff files.

To convert the files from JPEG 2000 to GeoTiff, we use the \emph{Geospatial Data Abstraction Library} (GDAL). This is a tool collection which acts as an abstraction layer for various geospatial data formats. It also includes a shell tool to translate several georeferenced image file formats, including JPEG 2000 and GeoTiff. The file \texttt{jp2\_to\_tif.sh} in~\cite{thesis-code20} shows a bash script using the \texttt{gdal\_translate} tool to convert all the JPEG 2000 files to the GeoTiff format.

With the files in GeoTiff format it is now possible to use the \texttt{raster2pgsql} tool to import them into a PostGIS raster table. The whole import process is automated with a Python script (file \texttt{tif\_to\_raster.py} in~\cite{thesis-code20}). It assumes that there is a database called \texttt{dop10rgbi\_nrw} with the PostGIS extension enabled.

In the first step, the script creates two database tables named \texttt{dop\_rgb} and \texttt{dop\_nir}. The \texttt{dop\_rgb} table has a PostGIS raster column with three raster bands to hold the color information for the DOPs. Simultaneously, the \texttt{dop\_nir} table also has a PostGIS raster column with only one raster band for the NIR values. Figure~\ref{fig:dop_entities} illustrates the structure of both tables in detal. It is reasonable to separate the color and NIR values as they will be used for different tasks later on.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{images/dop_entities}
    \caption[Database Table Structure for \texttt{dop\_rgb} and \texttt{dop\_nir}]
    {\textbf{Database Table Structure for \texttt{dop\_rgb} and \texttt{dop\_nir}}. Both tables share the same table layout. The \texttt{rast} columns store the raster information with SRID $25832$.}
    \label{fig:dop_entities}
\end{figure}

After the tables are created, the script loops through all the GeoTiff files and calls the \texttt{raster2pgsql} tool for every single one. That call returns a SQL insert statements enriched with the raster information in a binary representation. To execute those statements, it is possible to simply pipe the output of \texttt{raster2pgsql} into a \texttt{psql} command which is connected to the database.

The \texttt{raster2pgsql} tool provides a lot of arguments to properly configure the import of the data. Obviously it needs to know the name of the file to import and the name of the database table to insert the data to. For performance reasons it is very important to set an appropriate tile size for the raster. The original tile size of the GeoTiff files ($10000\times 10000$ pixels) was assessed to be too large. After some experiments, a tile size of $1000\times 1000$ pixels was found to work best for both the initial import and the later processing of the raster.

Another major configuration is the \emph{spatial reference id} (SRID). It also has to be passed as an argument, to ensure the data is imported correctly. The SRID indicates the map projection that is used to map the raster to the earth's surface. The dataset is provided with the SRID 25832. This SRID only covers a rectangular area on the European continent. Therefore it offers a high precision without much distortion in that area and is widely used for maps in Central Europe.

After all GeoTiff files are imported, the Python script creates a Generalized Search Tree (GiST) index for both tables. This takes into account the spatial character of the data and thus speeds up spatial queries like merging and intersecting on the tables significantly. For the same reason, the Python script also enforces some constraints on the raster columns of the tables. This makes sure that all the raster tiles share common properties like tile size, SRID and the number of raster bands.

As a last step of the Python script, it creates one last table named \texttt{geom\_bounds}. This table holds a single PostGIS geometry object defining the exact boundaries of the raster tiles. That allows for a quick way to calculate if a given region is included in the spatial extents of the raster without having to process the whole raster table all the time.

\subsection{Preparing the Labels}
\label{sec:prepare_labels}
For supervised learning, the models need pairs of input with the expected output. As described in the previous section, the DOPs serve as the input for the models. This section now explains how the labels for training were obtained.

Usually this task is done manually by lining out all segments of a tile and then assigning a class to each segment. To reduce the amount of work, we use another dataset from the GEOportal called Digital Basic Landscape Model~\cite{base-dlm20}. It describes topological features of the landscape in a vector data format. The dataset includes regions categorized by their respective land use. It is available for free download and also permits any use within the dl-de/zero-2-0 license. With some transformations, the data is well suited for the use as labels during the training of a model.

The categorized regions are provided as Shapefiles. Shapefile is a specific data format for vector-based geospatial objects. To have all data in a single source system, the Shapefiles are also imported into the PostGIS database. This also makes it easier to export the segmentation information later on for different tile sizes. Again, the import process is automated with a Python script (file \texttt{shp\_to\_geom.py} in~\cite{thesis-code20}).

PostGIS includes a tool called \texttt{shp2pgsql} to import Shapefiles into a database table with a PostGIS geometry column. It takes into account all the metadata that is listed in the Shapefile and creates separate columns for those values. The Python script loops over all the required Shapesfiles and calls the \texttt{shp2pgsql} tool passing some arguments like the target SRID. At first, each file is imported in its own database table. This is because each file contains a specific set of meta information resulting in different table layout for each file. The categorized regions are now represented as PostGIS geometry objects.

The original Shapesfiles enclose all regions of the State of North Rhine-Westphalia. Since the DOP und NIR datasets only consist of a smaller subregion, all geometry objects are cropped to that subregion in the next step. Geometry objects that are located outside of the boundaries are dropped entirely. During this process, the database tables of the different Shapefiles are merged into one single table. This resulting table has columns for an internal id, the object type, a textual object description and for the geometry object itself. As all the other meta information contained in the Shapefiles is not needed, it is dropped in this step.

The Shapefiles contain a few more categories than the segmentation in this thesis aims for. For example, the difference between industrial zones and housing zones is negligible for the purpose of emergency landings. Thus, the categories are mapped to six predefined classes (Fig.~\ref{fig:dop_label_all}). The mapping between the categories of the Shapefiles and the chosen classes is to be found in table~\ref{tab:category_mapping}.

\begin{table}[]
\centering
\small
\caption[Mapping from Shapefile Categories to Segmentation Classes]
{\textbf{Mapping from Shapefile Categories to Segmentation Classes}. The initial label set differentiates between more categories than needed. Therefore, some categories are merged into shared segmentation classes.}
\label{tab:category_mapping}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Shapefile} & \textbf{Object Code} & \textbf{Object Description}    & \textbf{Segmentation Class} \\ \hline
gew01\_f           & 44001                & running water                  & water                          \\ \hline
gew01\_f           & 44005                & harbor dock                    & water                          \\ \hline
gew01\_f           & 44006                & stagnant water                 & water                          \\ \hline
sie02\_f           & 41007                & specialized regions            & buildings                      \\ \hline
sie02\_f           & 41009                & cemetery                       & urban greens                   \\ \hline
sie02\_f           & 41002                & industrial zone                & buildings                      \\ \hline
sie02\_f           & 41010                & housing zone                   & buildings                      \\ \hline
sie02\_f           & 41008                & sports, recreation          & urban greens                   \\ \hline
sie02\_f           & 41005                & quarry, surface mining         & buildings                      \\ \hline
veg01\_f           & 43001                & agriculture                    & agriculture                    \\ \hline
veg02\_f           & 43002                & forest                         & forest                         \\ \hline
veg03\_f           & 43003                & woody, undergrowth             & forest                         \\ \hline
veg03\_f           & 43004                & heath                          & forest                         \\ \hline
veg03\_f           & 43007                & uncultivated zones             & agriculture                    \\ \hline
ver01\_f           & 42009                & urban squares                  & traffic                        \\ \hline
ver01\_f           & 42001                & road traffic                   & traffic                        \\ \hline
ver03\_f           & 42010                & rail traffic                   & traffic                        \\ \hline
\end{tabular}
\end{table}

The last step is to merge all geometry objects of the same class. The final table \texttt{geom\_segments} only contains six geometry objects, one for each class. This was done for convenience and performance reasons, since almost all operations performed on this table include some way of merging the geometry objects of the same class.

Figure~\ref{fig:dop_label_all} depicts the segmentation for the whole dataset with a color encoding. The most dominant classes are clearly forest and buildings. Water and traffic zones only take up a very small area and both are barely visible because of the scale of the illustration. The imbalance of the classes is an issue which is further addressed in Section~\ref{sec:dataset_considerations}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/dop_label_all}
    \caption[The Labels in the Dataset]
    {\textbf{The Labels in the Dataset}. Six predefined classes are used. Area distribution among classes is unbalanced. Dominant classes are \texttt{forest}, \texttt{buildings} and \texttt{agriculture}.}
    \label{fig:dop_label_all}
\end{figure}

\subsection{Export Images for Training}
\label{sec:image_export}
At this stage, all the data required for the training of network models is contained in the PostgreSQL database and can be queried in regions of arbitrary tile size. While it is possible to query each tile live during training, this is highly inefficient. Since the same data is fed into the network multiple times, the same query result would have to be computed multiple times during a training run (i.~e. once per epoch). Also, doing a full round of backpropagation with a single tile is by far faster than executing a query for a single tile. Depending on the architecture of the network, a single pass of backpropagation takes around $650~\text{ms}$ on average. Compared to that, the database query for a single tile measures to almost $20~\text{seconds}$.

To use the entire processing power during the training, all tiles are precomputed and saved in well-sized batches on a hard drive. That way, they only need to be loaded into memory and can then be used directly. However, depending on batch size and the hard drive's reading speed this might leave the hard drive as bottleneck. In the end, the process of feeding the data into the network is a balancing act between factors such as data compression, preprocessing pipelines and hardware availability.

For this thesis, the data is exported from the database and saved as image files in PNG format. This format offers a good tradeoff between file size on the hard drive and processing time required to decode the data. The width and height of the images depends on the shape of the input layer of the network to train and will thus be discussed later on in Sections~\ref{sec:unet_experiments} to~\ref{sec:wnet_experiments}. Each tile is stored in a separate file. That way it is very easy to randomize the order of the images for each epoch of the training, which helps in learning generalized weights.

The PNG image format is used for both the DOP footage and the segmentation labels. For the DOPs this works great, because they contain three color bands that can be stored in the RGB channels of a PNG file. It was found to be better for training if the input values are normalized to range $[0, 1]$ before feeding them to a network. Since the PNG files use 8 bit per color, this normalization can be achieved by dividing the color values by $255$.

In the image files the labels use color-encoding to differentiate between the classes. However, this is a bad representation for training, since the distance of the colors in the color space does not correlate with the similarity of the land use. This means the colors chosen for the classes would influence the segmentation predictions made by the network. Thus, after reading a label from a PNG file it is transformed to one-hot encoding.

In one-hot encoding, each pixel is assigned a vector with one value per class. The value for the class is set to $1$ if the pixel belongs to that specific class, and $0$ otherwise. That way, the distance between the classes is equal for each pair of classes, i.~e. there is no correlation between classes. The translation from color-encoding to one-hot encoding is done by simply mapping the color vectors to their respective one-hot encoded representation.

While the exact tile and label size depends on the network architecture, there is a general process how the image tiles are extracted from the database. This process is automated with multiple Python scripts (\texttt{scripts} folder in~\cite{thesis-code20}).

The first step is to define the bounding boxes of the tiles for each architecture in separate tables within the database. Each bounding box is represented by a  PostGIS geometry object. Figure~\ref{fig:geom_tiles_entities} shows the full structure of the tables. The images and labels are defined by two separate geometry objects, because for some architectures the dimensions of the predictions are different compared to the input.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/geom_tiles_entities}
    \caption[Database Table Structure for \texttt{geom\_tiles\_*}]
    {\textbf{Database Table Structure for \texttt{geom\_tiles\_*}}. Each reference architecture uses a unique arrangement of the dataset. Tables layouts are the same, but the image and labels sizes are different.}
    \label{fig:geom_tiles_entities}
\end{figure}

It is important to line up the tiles precisely with the DOP raster, so that the raster pixels are not distorted or cut off during the export. This does irrelevant for the labels, because they are stored in a vector format which is not based on pixels.

To extract the image files for those tile definitions, one straightforward way would be to join the raster table \texttt{dop\_rgb} with tile table containing the tile geometries using the PostGIS \texttt{ST\_Union} and \texttt{ST\_Intersection} functions. However, this was found to take a very long time to compute. Instead, a geospatial visualization software called \emph{QGIS} was used to do those computations. It offers a Python API which allows to run batch exports of a PostGIS raster table according to the bounding boxes defining the tiles.

The Python script to export all image files with QGIS can be found in the \texttt{scripts} folder in~\cite{thesis-code20}. Before running the script, QGIS has to be configured with all the layers necessary to render the tiles. QGIS offers to connect directly to a PostgreSQL database with the PostGIS extension. The raster columns from the database tables \texttt{dop\_rgb} and \texttt{dop\_nir} can simply be loaded as raster layers. For the segmentation labels multiple layers are required, each representing one class with a specified color. Thus, the geometry column from the \texttt{geom\_segments} table is loaded multiple times, each time filtered by a different segmentation class.

After all the layers have been configured, the script for the export can be executed. It reads all the tiling information from the database and distributes the rendering tasks to a few QGIS worker threads. Each worker thread is responsible for rendering the specific part of the map layers and saving it as PNG image file.

Since the tiles have been precisely aligned with the raster data, the RGB and NIR image files are pixel-perfect copies of the original dataset. However, as the labels are converted from vector space to pixel space during the export, QGIS performs color interpolation on the boundaries between adjacent segments. This is disadvantageous, because the interpolated pixels are no longer clearly assigned to a single class. To overcome this issue, another Python script iterates over all the label files and assigns proper colors to the interpolated pixels according to adjacent pixels.

Because of that process, it can happen that the segmentation maps in the exported label files slightly deviate from the labels provided in the initial dataset. However, in any case the difference is less than a few centimeters, which is acceptable in the context of this thesis. Figure~\ref{fig:dop_with_labels} shows some examples of images with their respective labels.

\begin{figure}[b]
    \centering
    \includegraphics[width=0.8\textwidth]{images/dop_plus_label}
    \caption[Selected DOPs with the Respective Labels]
    {\textbf{Selected DOPs with the Respective Labels}. Each image represents a cutout of $275\times 275~\text{meters}$ from the dataset. }
    \label{fig:dop_with_labels}
\end{figure}

\subsection{Considerations about the Dataset}
\label{sec:dataset_considerations}

Even though the chosen dataset generally offers many advantages, it still has some downsides. The two main points of concern are on one side the imbalanced distribution of classes and on the other side the label precision at segment edges.

Table~\ref{tab:seg-breakdown} shows the absolute and relative shares in area coverages of the classes in the dataset. Around $65\%$ of the dataset consists of area covered by forest. Furthermore, both traffic zones and water are below $1\%$ respectively. Forest, buildings and agriculture are the three dominant classes in this dataset. In total, those three classes make up almost $97\%$ of the dataset. This can also be seen in Fig.~\ref{fig:dop_label_all} on page~\pageref{fig:dop_label_all}.

\begin{table}[h]
\centering
\caption[Class Proportions measured over the entire Dataset]
{\textbf{Class Proportions measured over the entire Dataset}. Emphasizes imbalance between classes. \texttt{forest} class is overrepresented. \texttt{urban greens}, \texttt{water} and \texttt{traffic} classes are underrepresented.}
\label{tab:seg-breakdown}
\begin{tabular}{|l|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{\textbf{class}} &
  \multicolumn{1}{c|}{\textbf{total area [$m^2$]}} &
  \multicolumn{1}{c|}{\textbf{relative area [$\%$]}} \\ \hline
forest       & 162,554,698 & 65.40  \\ \hline
buildings    & 30,821,514  & 12.40  \\ \hline
urban greens & 5,715,026   & 2.30   \\ \hline
agriculture  & 47,331,698  & 19.04  \\ \hline
water        & 1,344,467   & 0.54   \\ \hline
traffic      & 788,878     & 0.32   \\ \hline
\end{tabular}
\end{table}

In general, such a striking imbalance between classes can have a significant impact on the model if not properly addressed. For example, it could happen that the model predicts the dominant class for all pixels all the time. In fact, a model can achieve $65\%$ categorical accuracy for the chosen dataset if it only predicts the \texttt{forest} class for every input. Obviously, this prediction would be useless for production use. There are many ways to handle this issue, some common ways are shown in~\cite{imbalanced_data09}. Section~\ref{sec:prepare_train_test} will further elaborate on this topic.

The second concern to raise about the dataset is about the label precision at the edges between adjacent segments. On a large scale, the labels match with the respective DOP footage. In detail, however, most edges between the segments are only roughly sketched. Figure~\ref{fig:label_considerations} shows some examples with common inaccuracies that appear throughout the whole set of labels.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/consideration_labels/44883}
        \caption{}
        \label{fig:label_considerations_a}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/consideration_labels/150815}
        \caption{}
        \label{fig:label_considerations_b}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/consideration_labels/69493}
        \caption{}
        \label{fig:label_considerations_c}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/consideration_labels/71270}
        \caption{}
        \label{fig:label_considerations_d}
    \end{subfigure}

    \caption[Poorly Outlined Edges on Adjacent Segments]
    {\textbf{Poorly Outlined Edges on Adjacent Segments}. The subfigures show common inaccuracies in the labels. This will have a negative effect on training outcome.}
    \label{fig:label_considerations}
\end{figure}

Figures~\ref{fig:label_considerations_a} and~\ref{fig:label_considerations_b} demonstrate that the \texttt{buildings} class not only includes houses, but the entire land parcel that belongs to the houses. In some cases, also the roads leading to the buildings are considered as buildings. For towns and villages, oftentimes the whole area is labelled with the \texttt{buildings} class, including gardens and streets.

Figure~\ref{fig:label_considerations_c} shows that roads and rails are ignored sometimes. Instead, the ground truth defines them as the same class as their surroundings. Figure~\ref{fig:label_considerations_d} depicts that rivers are mostly labelled as \texttt{water} correctly, but the riverbanks and small islands are outlined only roughly.

To get excellent predictions, training should ideally be performed with pixel-perfect labels. For this thesis, pixel-perfect predictions are not aspired. To identify emergency landing fields, we are looking for large contiguous areas, so minor inaccuracies at the edges are within tolerance. However, it is very likely that the inaccurate training data affects the quality of the predictions. This is something to keep in mind when evaluating the performance of the trained models, because it will also affect the metrics.

\clearpage
